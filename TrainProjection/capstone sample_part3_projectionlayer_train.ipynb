{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2921787ff8d54d73b3aa969038c99067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import  AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "\n",
    "device = 'cuda:1'\n",
    "\n",
    "model_name = \"microsoft/phi-2\"\n",
    "phi2_model_pretrained = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,  \n",
    "    torch_dtype = torch.float16\n",
    ")\n",
    "\n",
    "phi2_model_pretrained.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.bos_token = tokenizer.eos_token\n",
    "\n",
    "# special_tokens_dict = {'pad_token': '<|PAD|>', 'bos_token': '<|BOS|>'}\n",
    "# num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "# phi2_model_pretrained.resize_token_embeddings(len(tokenizer))  # Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e. the length of the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# model_name = \"microsoft/phi-2\"\n",
    "\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch.float16,\n",
    "# )\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     quantization_config=bnb_config,\n",
    "#     trust_remote_code=True\n",
    "# )\n",
    "# model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiForCausalLM(\n",
       "  (model): PhiModel(\n",
       "    (embed_tokens): Embedding(51200, 2560)\n",
       "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          (dense): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi2_model_pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd \n",
    "import json\n",
    "import os \n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_name(image_id_from_caption, list_image_info): \n",
    "    for img in list_image_info: \n",
    "        if img['id'] == image_id_from_caption: \n",
    "            img_name = img['file_name'].split('.')[0]\n",
    "            return img['file_name'].split('.')[0]\n",
    "    return 'NoImgNameFound'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path_captions_coco = '/media/App/amaranth/lavanya/Capstone_data/annotations_trainval2017/annotations/captions_train2017.json'\n",
    "\n",
    "# with open(file_path_captions_coco) as f:\n",
    "#    data = json.load(f)\n",
    "\n",
    "# captions_info = []\n",
    "# for a in data['annotations']: \n",
    "#     captions_info.append([a['image_id'], a['caption'], a['id']])\n",
    "\n",
    "# captions_info_df = pd.DataFrame(data=captions_info, columns=['image_id', 'caption', 'caption_id'])\n",
    "# captions_info_df['image_name'] = captions_info_df['image_id'].apply(lambda x: get_image_name(x, data['images']))\n",
    "# captions_info_df['image_name'] = captions_info_df['image_name'].apply(lambda x: '0'*(12-len(str(x))) + str(x))\n",
    "# captions_info_df.to_csv('captions_images_map_COCO_train2017.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2293959/1237926302.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  captions_info_df = pd.read_csv('captions_images_map_COCO_train2017.csv')\n"
     ]
    }
   ],
   "source": [
    "captions_info_df = pd.read_csv('captions_images_map_COCO_train2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>caption</th>\n",
       "      <th>caption_id</th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203564</td>\n",
       "      <td>A bicycle replica with a clock as the front wh...</td>\n",
       "      <td>37</td>\n",
       "      <td>203564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>322141</td>\n",
       "      <td>A room with blue walls and a white sink and door.</td>\n",
       "      <td>49</td>\n",
       "      <td>322141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16977</td>\n",
       "      <td>A car that seems to be parked illegally behind...</td>\n",
       "      <td>89</td>\n",
       "      <td>16977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106140</td>\n",
       "      <td>A large passenger airplane flying through the ...</td>\n",
       "      <td>98</td>\n",
       "      <td>106140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106140</td>\n",
       "      <td>There is a GOL plane taking off in a partly cl...</td>\n",
       "      <td>101</td>\n",
       "      <td>106140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591748</th>\n",
       "      <td>133071</td>\n",
       "      <td>a slice of bread is covered with a sour cream ...</td>\n",
       "      <td>829655</td>\n",
       "      <td>133071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591749</th>\n",
       "      <td>410182</td>\n",
       "      <td>A long plate hold some fries with some sliders...</td>\n",
       "      <td>829658</td>\n",
       "      <td>410182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591750</th>\n",
       "      <td>180285</td>\n",
       "      <td>Two women sit and pose with stuffed animals.</td>\n",
       "      <td>829665</td>\n",
       "      <td>180285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591751</th>\n",
       "      <td>133071</td>\n",
       "      <td>White Plate with a lot of guacamole and an ext...</td>\n",
       "      <td>829693</td>\n",
       "      <td>133071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591752</th>\n",
       "      <td>133071</td>\n",
       "      <td>A dinner plate has a lemon wedge garnishment.</td>\n",
       "      <td>829717</td>\n",
       "      <td>133071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>591753 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_id                                            caption  \\\n",
       "0         203564  A bicycle replica with a clock as the front wh...   \n",
       "1         322141  A room with blue walls and a white sink and door.   \n",
       "2          16977  A car that seems to be parked illegally behind...   \n",
       "3         106140  A large passenger airplane flying through the ...   \n",
       "4         106140  There is a GOL plane taking off in a partly cl...   \n",
       "...          ...                                                ...   \n",
       "591748    133071  a slice of bread is covered with a sour cream ...   \n",
       "591749    410182  A long plate hold some fries with some sliders...   \n",
       "591750    180285       Two women sit and pose with stuffed animals.   \n",
       "591751    133071  White Plate with a lot of guacamole and an ext...   \n",
       "591752    133071      A dinner plate has a lemon wedge garnishment.   \n",
       "\n",
       "       caption_id image_name  \n",
       "0              37     203564  \n",
       "1              49     322141  \n",
       "2              89      16977  \n",
       "3              98     106140  \n",
       "4             101     106140  \n",
       "...           ...        ...  \n",
       "591748     829655     133071  \n",
       "591749     829658     410182  \n",
       "591750     829665     180285  \n",
       "591751     829693     133071  \n",
       "591752     829717     133071  \n",
       "\n",
       "[591753 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_info_df['token_size'] = captions_info_df['caption'].apply(lambda x: tokenizer(x, return_tensors=\"pt\", \n",
    "                                               return_attention_mask=False).input_ids.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGxCAYAAACOSdkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5AUlEQVR4nO3df1xW9f3/8eelwCWSXGEEeBUma400sDVYhPYdlgE60Zq3z9pGkWzlbFrG0LXMTwtbYh9n6Iaf2nIuXeiHfXYztj7VEDLT/CCGJpuoH+tzy5+fQKwQ/HlxBef7RzcOHVEExR/j/bjfbtfNrnNe73Pe53U72bNzrnNdLsuyLAEAABioz6WeAAAAwKVCEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAnBBVFRUKC8vT4cPHz6n8aNGjVJcXFzPTuoiyc7O1pAhQy71NAB0AUEIwAVRUVGhOXPmnHMQ+mf21FNPqaSk5FJPA0AXBFzqCQBAb3P99ddf6ikA6CKuCAHocXl5efrZz34mSYqJiZHL5ZLL5dI777yj1tZWzZ8/XzfeeKPcbrciIiL0wAMP6MCBA2fdbklJifr376+HHnpIn3/+uSRp8+bNmjBhggYOHKh+/frplltu0X/+5386xi1btkwul0tr167VT37yE4WHh+uqq67SxIkT9fHHH3fr2A4dOqQf//jHio6Oltvt1tVXX62RI0fqrbfesmtOvTWWl5dn9+DUV3Z2tl3X3NysZ5991u7N1VdfrR/+8Ic6dOhQt+YIoOu4IgSgxz300EP67LPPVFhYqFdffVWDBg2SJA0bNkw/+clP9NJLL+mRRx5RRkaG9uzZo6eeekrvvPOO3n//fYWHh592mwsXLtTPfvYz5eXl6V//9V8lSWvXrtWYMWOUlJSk3/72t/J4PCouLtb3vvc9HT9+3BEy2uY1btw4rVy5Uvv379fPfvYz3X///Xr77be7fGxZWVl6//33NXfuXH3ta1/T4cOH9f777+vTTz/ttB9jxoxxLHv11Vf1q1/9SjfddJMkqbW1VXfffbfeffddPf744xoxYoT27t2rp59+WqNGjdLmzZsVHBzc5XkC6CILAC6AX/3qV5Yka/fu3faynTt3WpKsqVOnOmo3bdpkSbKefPJJe1lKSop10003WS0tLdYjjzxiBQUFWUVFRY5xN954o3XLLbdYfr/fsTwjI8MaNGiQ1dLSYlmWZb388sun3e/8+fMtSVZtbW2Xj+uKK66wcnJyOq2ZNGmSdd11151x/bvvvmv169fPuu+++6zW1lbLsizrP/7jPyxJ1qpVqxy1VVVVliTrhRde6PIcAXQdt8YAXDRr166VpA5Xam699VYNHTpUa9ascSw/efKk7rnnHq1YsUJlZWW677777HX/+7//q//5n/+xl33++ef269vf/rZqa2u1a9cux/YmTJjgeD98+HBJ0t69e7t8DLfeequWLVumZ599VpWVlfL7/V0eK0k7d+7UhAkTNGLECP3hD3+Qy+WSJL3++uu68sorNX78eMexfP3rX1dUVJTeeeedbu0HQNcQhABcNG23j9pulX2Z1+vtcHupvr5eq1evVnJyskaMGOFYd/DgQUnSzJkzFRgY6HhNnTpVkvTJJ584xlx11VWO9263W5J04sSJLh/Dn/70J02aNEm///3vlZycrIEDB+qBBx5QXV3dWcd+/PHHGjNmjK699lq9+uqrCgoKchzP4cOHFRQU1OF46urqOhwLgJ7BZ4QAXDRtQaS2tlbXXnutY93HH3/c4fNBgwcPVkFBgb7zne9o4sSJ+vOf/6x+/fpJkl07a9YsTZw48bT7i42N7elDUHh4uBYtWqRFixZp3759eu211/TEE0+ovr5epaWlZxzX1NSkb3/722ptbdWbb74pj8fTYbtXXXXVGbcxYMCAHj0OAF8gCAG4IE53teXOO++UJBUVFemb3/ymvbyqqko7d+7U7NmzO2wnLS1Nq1ev1rhx45SRkaG//vWvCgkJUWxsrG644Qb9/e9/V35+/gU+mtMbPHiwHnnkEa1Zs0b//d//fca65uZmfec739GePXu0YcOGDiFQkjIyMlRcXKyWlhYlJSVdyGkD+BKCEIALIj4+XpL061//WpMmTVJgYKBiY2P14x//WIWFherTp4/Gjh1rPzUWHR2tn/70p6fd1u233641a9ZozJgxSktLs6+o/O53v9PYsWOVnp6u7OxsXXPNNfrss8+0c+dOvf/++/rzn//co8fU2NioO+64Q5mZmbrxxhs1YMAAVVVVqbS09IxXpSTppz/9qd5++23l5+fr6NGjqqystNddffXVuv766/X9739fK1as0Le//W099thjuvXWWxUYGKgDBw5o7dq1uvvuu/Wd73ynR48HgHhqDMCFM2vWLMvr9Vp9+vSxJFlr1661WlparH/7t3+zvva1r1mBgYFWeHi4df/991v79+93jG17auzLampqrKioKOsb3/iGdejQIcuyLOvvf/+7de+991oRERFWYGCgFRUVZd15553Wb3/7W3tc21NjVVVVju2tXbvWnldXnDx50nr44Yet4cOHW6GhoVZwcLAVGxtrPf3009axY8fsulOfGktJSbEknfY1adIku87v91sLFiywbr75Zqtfv37WFVdcYd14443WlClTrA8//LBLcwTQPS7LsqxLlsIAAAAuIZ4aAwAAxuIzQgCgL77ZubW1tdOagAD+ygR6G64IAYCkZ555psP395z62rNnz6WeJoAexmeEAEBffI/R2X6Adfjw4Y4vQQTwz48gBAAAjMWtMQAAYCw++XcWra2t+vjjjzVgwAD7xxEBAMDlzbIsHTlyRF6vV336nPm6D0HoLD7++GNFR0df6mkAAIBzsH///tP+rE0bgtBZtP3Q4f79+xUaGtrt8X6/X2VlZUpLS1NgYGBPT++fCr1oRy+c6Ec7etGOXjjRj3Zd6UVTU5Oio6PP+oPFBKGzaLsdFhoaes5BqH///goNDeXEpRc2euFEP9rRi3b0wol+tOtOL872sRY+LA0AAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgrIBLPQH88xnyxBvnNM7d19L8W6W4vNXytbh6eFad2/PcuIu6PwDAPweuCAEAAGN1Kwjl5eXJ5XI5XlFRUfZ6y7KUl5cnr9er4OBgjRo1Stu3b3dsw+fz6dFHH1V4eLhCQkI0YcIEHThwwFHT0NCgrKwseTweeTweZWVl6fDhw46affv2afz48QoJCVF4eLimT5+u5uZmR822bduUkpKi4OBgXXPNNXrmmWdkWVZ3DhkAAPRi3b4idNNNN6m2ttZ+bdu2zV43f/58FRQUaPHixaqqqlJUVJRSU1N15MgRuyYnJ0clJSUqLi7Whg0bdPToUWVkZKilpcWuyczMVHV1tUpLS1VaWqrq6mplZWXZ61taWjRu3DgdO3ZMGzZsUHFxsVatWqUZM2bYNU1NTUpNTZXX61VVVZUKCwu1YMECFRQUdLtJAACgd+r2Z4QCAgIcV4HaWJalRYsWafbs2Zo4caIkafny5YqMjNTKlSs1ZcoUNTY2aunSpXrllVd01113SZKKiooUHR2tt956S+np6dq5c6dKS0tVWVmppKQkSdKSJUuUnJysXbt2KTY2VmVlZdqxY4f2798vr9crSXr++eeVnZ2tuXPnKjQ0VCtWrNDJkye1bNkyud1uxcXF6YMPPlBBQYFyc3Plcl3cz6gAAIDLT7eD0Icffiiv1yu3262kpCTl5+frK1/5inbv3q26ujqlpaXZtW63WykpKaqoqNCUKVO0ZcsW+f1+R43X61VcXJwqKiqUnp6ujRs3yuPx2CFIkm677TZ5PB5VVFQoNjZWGzduVFxcnB2CJCk9PV0+n09btmzRHXfcoY0bNyolJUVut9tRM2vWLO3Zs0cxMTGnPT6fzyefz2e/b2pqkiT5/X75/f7utssecy5jL1fuvud2e9Hdx3L8eTFdbv3vjefF+aAf7ehFO3rhRD/adaUXXe1Tt4JQUlKS/vjHP+prX/uaDh48qGeffVYjRozQ9u3bVVdXJ0mKjIx0jImMjNTevXslSXV1dQoKClJYWFiHmrbxdXV1ioiI6LDviIgIR82p+wkLC1NQUJCjZsiQIR3207buTEFo3rx5mjNnToflZWVl6t+//2nHdEV5efk5j73czL/1/Mb/MrG1ZybSDW+++eZF32dX9KbzoifQj3b0oh29cKIf7TrrxfHjx7u0jW4FobFjx9r/HB8fr+TkZF1//fVavny5brvtNknqcMvJsqyz3oY6teZ09T1R0/ZB6c7mM2vWLOXm5trvm5qaFB0drbS0NIWGhnZ6HKfj9/tVXl6u1NRUBQYGdnv85Sgub/U5jXP3sfTLxFY9tbmPfK0X99ZkTV76Rd3f2fTG8+J80I929KIdvXCiH+260ou2Ozpnc17fIxQSEqL4+Hh9+OGHuueeeyR9cbVl0KBBdk19fb19JSYqKkrNzc1qaGhwXBWqr6/XiBEj7JqDBw922NehQ4cc29m0aZNjfUNDg/x+v6Om7erQl/cjdbxq9WVut9txO61NYGDgeZ145zv+cnK+3wHka3Vd9O8Rulx735vOi55AP9rRi3b0wol+tOusF13t0Xl9j5DP59POnTs1aNAgxcTEKCoqynGZqrm5WevWrbNDTkJCggIDAx01tbW1qqmpsWuSk5PV2Nio9957z67ZtGmTGhsbHTU1NTWqra21a8rKyuR2u5WQkGDXrF+/3vFIfVlZmbxeb4dbZgAAwEzdCkIzZ87UunXrtHv3bm3atEn/8i//oqamJk2aNEkul0s5OTnKz89XSUmJampqlJ2drf79+yszM1OS5PF49OCDD2rGjBlas2aNtm7dqvvvv1/x8fH2U2RDhw7VmDFjNHnyZFVWVqqyslKTJ09WRkaGYmNjJUlpaWkaNmyYsrKytHXrVq1Zs0YzZ87U5MmT7dtXmZmZcrvdys7OVk1NjUpKSpSfn88TYwAAwNatW2MHDhzQD37wA33yySe6+uqrddttt6myslLXXXedJOnxxx/XiRMnNHXqVDU0NCgpKUllZWUaMGCAvY2FCxcqICBA9957r06cOKHRo0dr2bJl6tu3r12zYsUKTZ8+3X66bMKECVq8eLG9vm/fvnrjjTc0depUjRw5UsHBwcrMzNSCBQvsGo/Ho/Lyck2bNk2JiYkKCwtTbm6u4/M/AADAbN0KQsXFxZ2ud7lcysvLU15e3hlr+vXrp8LCQhUWFp6xZuDAgSoqKup0X4MHD9brr7/eaU18fLzWr1/faQ0AADAXvzUGAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGOdVxCaN2+eXC6XcnJy7GWWZSkvL09er1fBwcEaNWqUtm/f7hjn8/n06KOPKjw8XCEhIZowYYIOHDjgqGloaFBWVpY8Ho88Ho+ysrJ0+PBhR82+ffs0fvx4hYSEKDw8XNOnT1dzc7OjZtu2bUpJSVFwcLCuueYaPfPMM7Is63wOGwAA9BLnHISqqqr00ksvafjw4Y7l8+fPV0FBgRYvXqyqqipFRUUpNTVVR44csWtycnJUUlKi4uJibdiwQUePHlVGRoZaWlrsmszMTFVXV6u0tFSlpaWqrq5WVlaWvb6lpUXjxo3TsWPHtGHDBhUXF2vVqlWaMWOGXdPU1KTU1FR5vV5VVVWpsLBQCxYsUEFBwbkeNgAA6EUCzmXQ0aNHdd9992nJkiV69tln7eWWZWnRokWaPXu2Jk6cKElavny5IiMjtXLlSk2ZMkWNjY1aunSpXnnlFd11112SpKKiIkVHR+utt95Senq6du7cqdLSUlVWViopKUmStGTJEiUnJ2vXrl2KjY1VWVmZduzYof3798vr9UqSnn/+eWVnZ2vu3LkKDQ3VihUrdPLkSS1btkxut1txcXH64IMPVFBQoNzcXLlcrg7H5vP55PP57PdNTU2SJL/fL7/f3+1etY05l7GXK3ffc7ui5u5jOf68mC63/vfG8+J80I929KIdvXCiH+260ouu9sllncN9okmTJmngwIFauHChRo0apa9//etatGiRPvroI11//fV6//33dcstt9j1d999t6688kotX75cb7/9tkaPHq3PPvtMYWFhds3NN9+se+65R3PmzNEf/vAH5ebmdrgVduWVV2rhwoX64Q9/qF/84hf661//qr///e/2+oaGBg0cOFBvv/227rjjDj3wwANqbGzUX//6V7tm69at+sY3vqGPPvpIMTExHY4tLy9Pc+bM6bB85cqV6t+/f3dbBQAALoHjx48rMzNTjY2NCg0NPWNdt68IFRcX6/3331dVVVWHdXV1dZKkyMhIx/LIyEjt3bvXrgkKCnKEoLaatvF1dXWKiIjosP2IiAhHzan7CQsLU1BQkKNmyJAhHfbTtu50QWjWrFnKzc213zc1NSk6OlppaWmdNvJM/H6/ysvLlZqaqsDAwG6PvxzF5a0+p3HuPpZ+mdiqpzb3ka+149W4C6kmL/2i7u9seuN5cT7oRzt60Y5eONGPdl3pRdsdnbPpVhDav3+/HnvsMZWVlalfv35nrDv1lpNlWae9DdVZzenqe6Km7QLYmebjdrvldrs7LA8MDDyvE+98x19OfC3nF2J8ra7z3kZ3Xa69703nRU+gH+3oRTt64UQ/2nXWi672qFsflt6yZYvq6+uVkJCggIAABQQEaN26dfrNb36jgIAAx9WWL6uvr7fXRUVFqbm5WQ0NDZ3WHDx4sMP+Dx065Kg5dT8NDQ3y+/2d1tTX10vqeNUKAACYp1tBaPTo0dq2bZuqq6vtV2Jiou677z5VV1frK1/5iqKiolReXm6PaW5u1rp16zRixAhJUkJCggIDAx01tbW1qqmpsWuSk5PV2Nio9957z67ZtGmTGhsbHTU1NTWqra21a8rKyuR2u5WQkGDXrF+/3vFIfVlZmbxeb4dbZgAAwDzdujU2YMAAxcXFOZaFhIToqquuspfn5OQoPz9fN9xwg2644Qbl5+erf//+yszMlCR5PB49+OCDmjFjhq666ioNHDhQM2fOVHx8vP0U2dChQzVmzBhNnjxZv/vd7yRJP/7xj5WRkaHY2FhJUlpamoYNG6asrCz96le/0meffaaZM2dq8uTJ9md5MjMzNWfOHGVnZ+vJJ5/Uhx9+qPz8fP3iF7846606AADQ+53T4/Odefzxx3XixAlNnTpVDQ0NSkpKUllZmQYMGGDXLFy4UAEBAbr33nt14sQJjR49WsuWLVPfvn3tmhUrVmj69OlKS0uTJE2YMEGLFy+21/ft21dvvPGGpk6dqpEjRyo4OFiZmZlasGCBXePxeFReXq5p06YpMTFRYWFhys3NdXwYGgAAmOu8g9A777zjeO9yuZSXl6e8vLwzjunXr58KCwtVWFh4xpqBAweqqKio030PHjxYr7/+eqc18fHxWr9+fac1AADATPzWGAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYq1tB6MUXX9Tw4cMVGhqq0NBQJScn629/+5u93rIs5eXlyev1Kjg4WKNGjdL27dsd2/D5fHr00UcVHh6ukJAQTZgwQQcOHHDUNDQ0KCsrSx6PRx6PR1lZWTp8+LCjZt++fRo/frxCQkIUHh6u6dOnq7m52VGzbds2paSkKDg4WNdcc42eeeYZWZbVnUMGAAC9WLeC0LXXXqvnnntOmzdv1ubNm3XnnXfq7rvvtsPO/PnzVVBQoMWLF6uqqkpRUVFKTU3VkSNH7G3k5OSopKRExcXF2rBhg44ePaqMjAy1tLTYNZmZmaqurlZpaalKS0tVXV2trKwse31LS4vGjRunY8eOacOGDSouLtaqVas0Y8YMu6apqUmpqanyer2qqqpSYWGhFixYoIKCgnNuFgAA6F0CulM8fvx4x/u5c+fqxRdfVGVlpYYNG6ZFixZp9uzZmjhxoiRp+fLlioyM1MqVKzVlyhQ1NjZq6dKleuWVV3TXXXdJkoqKihQdHa233npL6enp2rlzp0pLS1VZWamkpCRJ0pIlS5ScnKxdu3YpNjZWZWVl2rFjh/bv3y+v1ytJev7555Wdna25c+cqNDRUK1as0MmTJ7Vs2TK53W7FxcXpgw8+UEFBgXJzc+Vyuc67eQAA4J9bt4LQl7W0tOjPf/6zjh07puTkZO3evVt1dXVKS0uza9xut1JSUlRRUaEpU6Zoy5Yt8vv9jhqv16u4uDhVVFQoPT1dGzdulMfjsUOQJN12223yeDyqqKhQbGysNm7cqLi4ODsESVJ6erp8Pp+2bNmiO+64Qxs3blRKSorcbrejZtasWdqzZ49iYmJOe1w+n08+n89+39TUJEny+/3y+/3d7lPbmHMZe7ly9z2324vuPpbjz4vpcut/bzwvzgf9aEcv2tELJ/rRriu96Gqfuh2Etm3bpuTkZJ08eVJXXHGFSkpKNGzYMFVUVEiSIiMjHfWRkZHau3evJKmurk5BQUEKCwvrUFNXV2fXREREdNhvRESEo+bU/YSFhSkoKMhRM2TIkA77aVt3piA0b948zZkzp8PysrIy9e/f/7RjuqK8vPycx15u5t96fuN/mdjaMxPphjfffPOi77MretN50RPoRzt60Y5eONGPdp314vjx413aRreDUGxsrKqrq3X48GGtWrVKkyZN0rp16+z1p95ysizrrLehTq05XX1P1LR9ULqz+cyaNUu5ubn2+6amJkVHRystLU2hoaGdHsfp+P1+lZeXKzU1VYGBgd0efzmKy1t9TuPcfSz9MrFVT23uI1/rxb01WZOXflH3dza98bw4H/SjHb1oRy+c6Ee7rvSi7Y7O2XQ7CAUFBemrX/2qJCkxMVFVVVX69a9/rZ///OeSvrjaMmjQILu+vr7evhITFRWl5uZmNTQ0OK4K1dfXa8SIEXbNwYMHO+z30KFDju1s2rTJsb6hoUF+v99R03Z16Mv7kTpetfoyt9vtuJ3WJjAw8LxOvPMdfznxtZxfiPG1us57G911ufa+N50XPYF+tKMX7eiFE/1o11kvutqj8/4eIcuy5PP5FBMTo6ioKMdlqubmZq1bt84OOQkJCQoMDHTU1NbWqqamxq5JTk5WY2Oj3nvvPbtm06ZNamxsdNTU1NSotrbWrikrK5Pb7VZCQoJds379escj9WVlZfJ6vR1umQEAADN1Kwg9+eSTevfdd7Vnzx5t27ZNs2fP1jvvvKP77rtPLpdLOTk5ys/PV0lJiWpqapSdna3+/fsrMzNTkuTxePTggw9qxowZWrNmjbZu3ar7779f8fHx9lNkQ4cO1ZgxYzR58mRVVlaqsrJSkydPVkZGhmJjYyVJaWlpGjZsmLKysrR161atWbNGM2fO1OTJk+3bV5mZmXK73crOzlZNTY1KSkqUn5/PE2MAAMDWrVtjBw8eVFZWlmpra+XxeDR8+HCVlpYqNTVVkvT444/rxIkTmjp1qhoaGpSUlKSysjINGDDA3sbChQsVEBCge++9VydOnNDo0aO1bNky9e3b165ZsWKFpk+fbj9dNmHCBC1evNhe37dvX73xxhuaOnWqRo4cqeDgYGVmZmrBggV2jcfjUXl5uaZNm6bExESFhYUpNzfX8fkfAABgtm4FoaVLl3a63uVyKS8vT3l5eWes6devnwoLC1VYWHjGmoEDB6qoqKjTfQ0ePFivv/56pzXx8fFav359pzUAAMBc/NYYAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABirW0Fo3rx5+uY3v6kBAwYoIiJC99xzj3bt2uWosSxLeXl58nq9Cg4O1qhRo7R9+3ZHjc/n06OPPqrw8HCFhIRowoQJOnDggKOmoaFBWVlZ8ng88ng8ysrK0uHDhx01+/bt0/jx4xUSEqLw8HBNnz5dzc3Njppt27YpJSVFwcHBuuaaa/TMM8/IsqzuHDYAAOiluhWE1q1bp2nTpqmyslLl5eX6/PPPlZaWpmPHjtk18+fPV0FBgRYvXqyqqipFRUUpNTVVR44csWtycnJUUlKi4uJibdiwQUePHlVGRoZaWlrsmszMTFVXV6u0tFSlpaWqrq5WVlaWvb6lpUXjxo3TsWPHtGHDBhUXF2vVqlWaMWOGXdPU1KTU1FR5vV5VVVWpsLBQCxYsUEFBwTk1CwAA9C4B3SkuLS11vH/55ZcVERGhLVu26Fvf+pYsy9KiRYs0e/ZsTZw4UZK0fPlyRUZGauXKlZoyZYoaGxu1dOlSvfLKK7rrrrskSUVFRYqOjtZbb72l9PR07dy5U6WlpaqsrFRSUpIkacmSJUpOTtauXbsUGxursrIy7dixQ/v375fX65UkPf/888rOztbcuXMVGhqqFStW6OTJk1q2bJncbrfi4uL0wQcfqKCgQLm5uXK5XOfdQAAA8M+rW0HoVI2NjZKkgQMHSpJ2796turo6paWl2TVut1spKSmqqKjQlClTtGXLFvn9fkeN1+tVXFycKioqlJ6ero0bN8rj8dghSJJuu+02eTweVVRUKDY2Vhs3blRcXJwdgiQpPT1dPp9PW7Zs0R133KGNGzcqJSVFbrfbUTNr1izt2bNHMTExHY7J5/PJ5/PZ75uamiRJfr9ffr+/2z1qG3MuYy9X7r7ndmvR3cdy/HkxXW79743nxfmgH+3oRTt64UQ/2nWlF13t0zkHIcuylJubq9tvv11xcXGSpLq6OklSZGSkozYyMlJ79+61a4KCghQWFtahpm18XV2dIiIiOuwzIiLCUXPqfsLCwhQUFOSoGTJkSIf9tK07XRCaN2+e5syZ02F5WVmZ+vfvf5pOdE15efk5j73czL/1/Mb/MrG1ZybSDW+++eZF32dX9KbzoifQj3b0oh29cKIf7TrrxfHjx7u0jXMOQo888oj+8Y9/aMOGDR3WnXrLybKss96GOrXmdPU9UdP2QekzzWfWrFnKzc213zc1NSk6OlppaWkKDQ3t9BhOx+/3q7y8XKmpqQoMDOz2+MtRXN7qcxrn7mPpl4mtempzH/laL+5tyZq89Iu6v7PpjefF+aAf7ehFO3rhRD/adaUXbXd0zuacgtCjjz6q1157TevXr9e1115rL4+KipL0xdWWQYMG2cvr6+vtKzFRUVFqbm5WQ0OD46pQfX29RowYYdccPHiww34PHTrk2M6mTZsc6xsaGuT3+x01bVeHvrwfqeNVqzZut9txK61NYGDgeZ145zv+cuJrOb8Q42t1nfc2uuty7X1vOi96Av1oRy/a0Qsn+tGus150tUfdemrMsiw98sgjevXVV/X22293uLUUExOjqKgox6Wq5uZmrVu3zg45CQkJCgwMdNTU1taqpqbGrklOTlZjY6Pee+89u2bTpk1qbGx01NTU1Ki2ttauKSsrk9vtVkJCgl2zfv16xyP1ZWVl8nq9HW6ZAQAA83QrCE2bNk1FRUVauXKlBgwYoLq6OtXV1enEiROSvrjdlJOTo/z8fJWUlKimpkbZ2dnq37+/MjMzJUkej0cPPvigZsyYoTVr1mjr1q26//77FR8fbz9FNnToUI0ZM0aTJ09WZWWlKisrNXnyZGVkZCg2NlaSlJaWpmHDhikrK0tbt27VmjVrNHPmTE2ePNm+hZWZmSm3263s7GzV1NSopKRE+fn5PDEGAAAkdfPW2IsvvihJGjVqlGP5yy+/rOzsbEnS448/rhMnTmjq1KlqaGhQUlKSysrKNGDAALt+4cKFCggI0L333qsTJ05o9OjRWrZsmfr27WvXrFixQtOnT7efLpswYYIWL15sr+/bt6/eeOMNTZ06VSNHjlRwcLAyMzO1YMECu8bj8ai8vFzTpk1TYmKiwsLClJub6/gMEAAAMFe3glBXvpHZ5XIpLy9PeXl5Z6zp16+fCgsLVVhYeMaagQMHqqioqNN9DR48WK+//nqnNfHx8Vq/fn2nNQAAwEz81hgAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGKvbQWj9+vUaP368vF6vXC6X/vKXvzjWW5alvLw8eb1eBQcHa9SoUdq+fbujxufz6dFHH1V4eLhCQkI0YcIEHThwwFHT0NCgrKwseTweeTweZWVl6fDhw46affv2afz48QoJCVF4eLimT5+u5uZmR822bduUkpKi4OBgXXPNNXrmmWdkWVZ3DxsAAPRC3Q5Cx44d080336zFixefdv38+fNVUFCgxYsXq6qqSlFRUUpNTdWRI0fsmpycHJWUlKi4uFgbNmzQ0aNHlZGRoZaWFrsmMzNT1dXVKi0tVWlpqaqrq5WVlWWvb2lp0bhx43Ts2DFt2LBBxcXFWrVqlWbMmGHXNDU1KTU1VV6vV1VVVSosLNSCBQtUUFDQ3cMGAAC9UEB3B4wdO1Zjx4497TrLsrRo0SLNnj1bEydOlCQtX75ckZGRWrlypaZMmaLGxkYtXbpUr7zyiu666y5JUlFRkaKjo/XWW28pPT1dO3fuVGlpqSorK5WUlCRJWrJkiZKTk7Vr1y7FxsaqrKxMO3bs0P79++X1eiVJzz//vLKzszV37lyFhoZqxYoVOnnypJYtWya32624uDh98MEHKigoUG5urlwu1zk1DQAA9A7dDkKd2b17t+rq6pSWlmYvc7vdSklJUUVFhaZMmaItW7bI7/c7arxer+Li4lRRUaH09HRt3LhRHo/HDkGSdNttt8nj8aiiokKxsbHauHGj4uLi7BAkSenp6fL5fNqyZYvuuOMObdy4USkpKXK73Y6aWbNmac+ePYqJielwDD6fTz6fz37f1NQkSfL7/fL7/d3uSduYcxl7uXL3Pbdbi+4+luPPi+ly639vPC/OB/1oRy/a0Qsn+tGuK73oap96NAjV1dVJkiIjIx3LIyMjtXfvXrsmKChIYWFhHWraxtfV1SkiIqLD9iMiIhw1p+4nLCxMQUFBjpohQ4Z02E/butMFoXnz5mnOnDkdlpeVlal///6nP/AuKC8vP+exl5v5t57f+F8mtvbMRLrhzTffvOj77IredF70BPrRjl60oxdO9KNdZ704fvx4l7bRo0Gozam3nCzLOuttqFNrTlffEzVtH5Q+03xmzZql3Nxc+31TU5Oio6OVlpam0NDQTo/hdPx+v8rLy5WamqrAwMBuj78cxeWtPqdx7j6WfpnYqqc295Gv9eLelqzJS7+o+zub3nhenA/60Y5etKMXTvSjXVd60XZH52x6NAhFRUVJ+uJqy6BBg+zl9fX19pWYqKgoNTc3q6GhwXFVqL6+XiNGjLBrDh482GH7hw4dcmxn06ZNjvUNDQ3y+/2OmrarQ1/ej9TxqlUbt9vtuJXWJjAw8LxOvPMdfznxtZxfiPG1us57G911ufa+N50XPYF+tKMX7eiFE/1o11kvutqjHv0eoZiYGEVFRTkuVTU3N2vdunV2yElISFBgYKCjpra2VjU1NXZNcnKyGhsb9d5779k1mzZtUmNjo6OmpqZGtbW1dk1ZWZncbrcSEhLsmvXr1zseqS8rK5PX6+1wywwAAJin20Ho6NGjqq6uVnV1taQvPiBdXV2tffv2yeVyKScnR/n5+SopKVFNTY2ys7PVv39/ZWZmSpI8Ho8efPBBzZgxQ2vWrNHWrVt1//33Kz4+3n6KbOjQoRozZowmT56syspKVVZWavLkycrIyFBsbKwkKS0tTcOGDVNWVpa2bt2qNWvWaObMmZo8ebJ9CyszM1Nut1vZ2dmqqalRSUmJ8vPzeWIMAABIOodbY5s3b9Ydd9xhv2/7PM2kSZO0bNkyPf744zpx4oSmTp2qhoYGJSUlqaysTAMGDLDHLFy4UAEBAbr33nt14sQJjR49WsuWLVPfvn3tmhUrVmj69On202UTJkxwfHdR37599cYbb2jq1KkaOXKkgoODlZmZqQULFtg1Ho9H5eXlmjZtmhITExUWFqbc3FzHZ4AAAIC5uh2ERo0a1ek3M7tcLuXl5SkvL++MNf369VNhYaEKCwvPWDNw4EAVFRV1OpfBgwfr9ddf77QmPj5e69ev77QGAACYid8aAwAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADG6tFfnwcuV0OeeONST8HB3dfS/FuluLzV8rWc/nfv9jw37iLPCgDMwxUhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWEYEoRdeeEExMTHq16+fEhIS9O67717qKQEAgMtAwKWewIX2pz/9STk5OXrhhRc0cuRI/e53v9PYsWO1Y8cODR48+FJPDzijIU+8camn0G17nht3qacAAN3S668IFRQU6MEHH9RDDz2koUOHatGiRYqOjtaLL754qacGAAAusV59Rai5uVlbtmzRE0884VielpamioqK047x+Xzy+Xz2+8bGRknSZ599Jr/f3+05+P1+HT9+XJ9++qkCAwO7Pf5yFPD5sXMb12rp+PFWBfj7qKXV1cOz+ufSW3vx6aefntO43vjvybmiF+3ohRP9aNeVXhw5ckSSZFlWp9vq1UHok08+UUtLiyIjIx3LIyMjVVdXd9ox8+bN05w5czosj4mJuSBzNE3mpZ7AZaQ39iL8+Us9AwBwOnLkiDwezxnX9+og1Mblcv4ft2VZHZa1mTVrlnJzc+33ra2t+uyzz3TVVVedcUxnmpqaFB0drf379ys0NLTb43sTetGOXjjRj3b0oh29cKIf7brSC8uydOTIEXm93k631auDUHh4uPr27dvh6k99fX2Hq0Rt3G633G63Y9mVV1553nMJDQ01/sRtQy/a0Qsn+tGOXrSjF070o93ZetHZlaA2vfrD0kFBQUpISFB5ebljeXl5uUaMGHGJZgUAAC4XvfqKkCTl5uYqKytLiYmJSk5O1ksvvaR9+/bp4YcfvtRTAwAAl1ivD0Lf+9739Omnn+qZZ55RbW2t4uLi9Oabb+q66667KPt3u916+umnO9xuMxG9aEcvnOhHO3rRjl440Y92PdkLl3W258oAAAB6qV79GSEAAIDOEIQAAICxCEIAAMBYBCEAAGAsghAAADAWQegCeuGFFxQTE6N+/fopISFB77777qWe0kWxfv16jR8/Xl6vVy6XS3/5y18c6y3LUl5enrxer4KDgzVq1Cht37790kz2Aps3b56++c1vasCAAYqIiNA999yjXbt2OWpM6ceLL76o4cOH298Em5ycrL/97W/2elP6cDrz5s2Ty+VSTk6OvcyUfuTl5cnlcjleUVFR9npT+vBl//d//6f7779fV111lfr376+vf/3r2rJli73elJ4MGTKkw7nhcrk0bdo0ST3XB4LQBfKnP/1JOTk5mj17trZu3ar/9//+n8aOHat9+/Zd6qldcMeOHdPNN9+sxYsXn3b9/PnzVVBQoMWLF6uqqkpRUVFKTU21fym4N1m3bp2mTZumyspKlZeX6/PPP1daWpqOHTtm15jSj2uvvVbPPfecNm/erM2bN+vOO+/U3Xffbf/FZUofTlVVVaWXXnpJw4cPdyw3qR833XSTamtr7de2bdvsdSb1QZIaGho0cuRIBQYG6m9/+5t27Nih559/3vFTT6b0pKqqynFetP1KxHe/+11JPdgHCxfErbfeaj388MOOZTfeeKP1xBNPXKIZXRqSrJKSEvt9a2urFRUVZT333HP2spMnT1oej8f67W9/ewlmeHHV19dbkqx169ZZlkU/wsLCrN///vfG9uHIkSPWDTfcYJWXl1spKSnWY489ZlmWWefF008/bd18882nXWdSH9r8/Oc/t26//fYzrjexJ20ee+wx6/rrr7daW1t7tA9cEboAmpubtWXLFqWlpTmWp6WlqaKi4hLN6vKwe/du1dXVOXrjdruVkpJiRG8aGxslSQMHDpRkbj9aWlpUXFysY8eOKTk52dg+TJs2TePGjdNdd93lWG5aPz788EN5vV7FxMTo+9//vj766CNJ5vVBkl577TUlJibqu9/9riIiInTLLbdoyZIl9noTeyJ98d/VoqIi/ehHP5LL5erRPhCELoBPPvlELS0tHX7hPjIyUnV1dZdoVpeHtuM3sTeWZSk3N1e333674uLiJJnXj23btumKK66Q2+3Www8/rJKSEg0bNsy4PkhScXGx3n//fc2bN6/DOpP6kZSUpD/+8Y9avXq1lixZorq6Oo0YMUKffvqpUX1o89FHH+nFF1/UDTfcoNWrV+vhhx/W9OnT9cc//lGSWefGl/3lL3/R4cOHlZ2dLaln+9Drf2vsUnK5XI73lmV1WGYqE3vzyCOP6B//+Ic2bNjQYZ0p/YiNjVV1dbUOHz6sVatWadKkSVq3bp293pQ+7N+/X4899pjKysrUr1+/M9aZ0I+xY8fa/xwfH6/k5GRdf/31Wr58uW677TZJZvShTWtrqxITE5Wfny9JuuWWW7R9+3a9+OKLeuCBB+w6k3oiSUuXLtXYsWPl9Xody3uiD1wRugDCw8PVt2/fDqm0vr6+Q3o1TdvTIKb15tFHH9Vrr72mtWvX6tprr7WXm9aPoKAgffWrX1ViYqLmzZunm2++Wb/+9a+N68OWLVtUX1+vhIQEBQQEKCAgQOvWrdNvfvMbBQQE2MdsSj++LCQkRPHx8frwww+NOy8kadCgQRo2bJhj2dChQ+0HbUzsyd69e/XWW2/poYcespf1ZB8IQhdAUFCQEhIS7E+4tykvL9eIESMu0awuDzExMYqKinL0prm5WevWreuVvbEsS4888oheffVVvf3224qJiXGsN60fp7IsSz6fz7g+jB49Wtu2bVN1dbX9SkxM1H333afq6mp95StfMaofX+bz+bRz504NGjTIuPNCkkaOHNnhKzY++OADXXfddZLM/Dvj5ZdfVkREhMaNG2cv69E+9MhHudFBcXGxFRgYaC1dutTasWOHlZOTY4WEhFh79uy51FO74I4cOWJt3brV2rp1qyXJKigosLZu3Wrt3bvXsizLeu655yyPx2O9+uqr1rZt26wf/OAH1qBBg6ympqZLPPOe95Of/MTyeDzWO++8Y9XW1tqv48eP2zWm9GPWrFnW+vXrrd27d1v/+Mc/rCeffNLq06ePVVZWZlmWOX04ky8/NWZZ5vRjxowZ1jvvvGN99NFHVmVlpZWRkWENGDDA/rvSlD60ee+996yAgABr7ty51ocffmitWLHC6t+/v1VUVGTXmNSTlpYWa/DgwdbPf/7zDut6qg8EoQvo3//9363rrrvOCgoKsr7xjW/Yj0z3dmvXrrUkdXhNmjTJsqwvHv98+umnraioKMvtdlvf+ta3rG3btl3aSV8gp+uDJOvll1+2a0zpx49+9CP734err77aGj16tB2CLMucPpzJqUHIlH5873vfswYNGmQFBgZaXq/XmjhxorV9+3Z7vSl9+LL/+q//suLi4iy3223deOON1ksvveRYb1JPVq9ebUmydu3a1WFdT/XBZVmWdR5XrAAAAP5p8RkhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABjr/wMe6QUbqZ3NBgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = captions_info_df.hist(['token_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py    \n",
    "import numpy as np    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCO_CLIP_Dataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self, caption_file, embedding_path, tokenizer, max_token_len_data):\n",
    "        \n",
    "        self.embedding_path = embedding_path\n",
    "        self.caption_file = caption_file\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len_data = max_token_len_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.caption_file)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        row = self.caption_file.iloc[[index]]\n",
    "\n",
    "        df_img = row['image_id'].values[0]\n",
    "        img_base_name = '0'*(12-len(str(df_img))) + str(df_img)\n",
    "        img_base_name = img_base_name.replace(' ', '0')\n",
    "        img_clip_embedding_path = os.path.join(self.embedding_path, f'{img_base_name}.h5')\n",
    "\n",
    "        np_array_embed_img = h5py.File(img_clip_embedding_path,'r+')['image_features'][()]\n",
    "        \n",
    "        img_caption = row['caption'].values[0] ## Tokenize this \n",
    "        img_caption_tokenized = self.tokenizer(img_caption, return_tensors=\"pt\", \n",
    "                                               return_attention_mask=False).input_ids\n",
    "\n",
    "        ## put bos, eos, and padding for batch         \n",
    "        # input_bos = torch.cat((torch.tensor(self.tokenizer.bos_token_id).view((1,1)), \n",
    "        #                                                img_caption_tokenized), dim=1)\n",
    "\n",
    "        input_bos = img_caption_tokenized\n",
    "\n",
    "        input_eos = torch.cat((input_bos, \n",
    "                               torch.tensor(self.tokenizer.eos_token_id).view((1,1))), dim=1)\n",
    "        \n",
    "        if (self.max_token_len_data - input_eos.shape[1]) > 0: \n",
    "            input_final =  torch.cat((input_eos,torch.tensor([self.tokenizer.pad_token_id]*(self.max_token_len_data - input_eos.shape[1])).unsqueeze(0)), dim=1)\n",
    "        else: \n",
    "            input_final = input_eos\n",
    "        \n",
    "        return torch.tensor(np_array_embed_img).squeeze(0), input_final.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_exists(image_id, fpath = '/media/App/amaranth/lavanya/Capstone_data/clip_features_base_patch32/'): \n",
    "\n",
    "    n = '0'*(12-len(str(image_id))) + str(image_id) + '.h5'\n",
    "    fp = os.path.join(fpath, n)\n",
    "\n",
    "    if os.path.exists(fp): \n",
    "        return True\n",
    "    else: \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### captions_info_df contains for 1 image multiple entries, lets reduce keeping one image, one entry. \n",
    "captions_info_df_subset = captions_info_df.drop_duplicates(subset='image_id', keep='first')\n",
    "captions_info_df_subset = captions_info_df_subset[captions_info_df_subset['token_size'] <=30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_token_len_data = 75\n",
    "dataset = COCO_CLIP_Dataset(captions_info_df_subset, \n",
    "                            '/media/App/amaranth/lavanya/Capstone_data/clip_features_base_patch32/', \n",
    "                            tokenizer, max_token_len_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleResBlock(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.pre_norm = nn.LayerNorm(input_size)\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(input_size, input_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(input_size, input_size)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.pre_norm(x)\n",
    "        return x + self.proj(x)\n",
    "    \n",
    "class Phi2wrapper(nn.Module):\n",
    "    \n",
    "    #This defines the structure of the NN.\n",
    "    def __init__(self, input_dim_CLIP=768, input_dim_phi2=2560, \n",
    "                 phi2_model=phi2_model_pretrained, \n",
    "                 max_token_len_data=max_token_len_data, tokenizer=tokenizer, teacher_forcing = 3, device=device):\n",
    "        \n",
    "        super(Phi2wrapper, self).__init__()\n",
    "\n",
    "        self.input_dim_CLIP = input_dim_CLIP\n",
    "        self.input_dim_phi2 = input_dim_phi2\n",
    "        self.projection_img = nn.Linear(self.input_dim_CLIP, self.input_dim_phi2, \n",
    "                                        bias=False)\n",
    "                                                                                                                                                           \n",
    "        self.resblock = SimpleResBlock(self.input_dim_phi2)\n",
    "        self.phi2_model = phi2_model\n",
    "        self.max_token_len_data = max_token_len_data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.device = device\n",
    "        self.teacher_forcing = teacher_forcing\n",
    "\n",
    "        bos = self.tokenizer(\"Image: \", return_tensors=\"pt\", return_attention_mask=False)\n",
    "        eoi = self.tokenizer(\" Caption: \", return_tensors=\"pt\", return_attention_mask=False)\n",
    "    \n",
    "        self.bos_embedding = self.phi2_model.get_input_embeddings()(bos.input_ids.to(self.device)).squeeze(0)\n",
    "        self.eoi_embedding = self.phi2_model.get_input_embeddings()(eoi.input_ids.to(self.device)).squeeze(0)\n",
    "        self.eos_embedding = self.phi2_model.get_input_embeddings()(torch.tensor(self.tokenizer.eos_token_id).to(self.device)).unsqueeze(0)\n",
    "\n",
    "    def forward(self, x, input_caption):\n",
    "\n",
    "        x = self.projection_img(x)\n",
    "        x = self.resblock(x)\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        x = torch.cat((self.bos_embedding.repeat(batch_size,1,1), x, \n",
    "                    self.eoi_embedding.repeat(batch_size,1,1)), dim=1)\n",
    "        \n",
    "        loss = 0 \n",
    "        word_output_pred_tokens = None\n",
    "\n",
    "        for idx in range(input_caption.shape[1]): \n",
    "            \n",
    "            out_phi = self.phi2_model.model.layers[0](x.to(torch.float16))\n",
    "            \n",
    "            for layer_idx in range(1, 32): \n",
    "                out_phi = self.phi2_model.model.layers[layer_idx](out_phi[0])\n",
    "                \n",
    "            out_phi = self.phi2_model.model.final_layernorm(out_phi[0])\n",
    "            out_phi = self.phi2_model.lm_head(zzout_phi) ## torch.Size([batch, 55, 50297])\n",
    "            \n",
    "            next_word = torch.argmax(out_phi[:, -1, :], dim=-1) ## [batch]\n",
    "            \n",
    "            caption_word_token = input_caption[:,idx]\n",
    "            \n",
    "#             print(\"Decode:\", self.tokenizer.decode(next_word))\n",
    "#             print(\"Decode gt:\", self.tokenizer.decode(caption_word_token))\n",
    "            \n",
    "            no_of_pad_tokens = sum(torch.eq(torch.tensor([self.tokenizer.pad_token_id]*batch_size).to(self.device), caption_word_token))\n",
    "            \n",
    "            if no_of_pad_tokens == torch.tensor(batch_size): \n",
    "                break \n",
    "                \n",
    "            if idx>=self.teacher_forcing:\n",
    "#                 print(idx, \" next word model\", self.tokenizer.decode(next_word))\n",
    "                caption_word_embedding = self.phi2_model.get_input_embeddings()(next_word).unsqueeze(1)\n",
    "            else:\n",
    "#                 print(idx, \" next word ground truth\", self.tokenizer.decode(caption_word_token))\n",
    "                caption_word_embedding = self.phi2_model.get_input_embeddings()(caption_word_token).unsqueeze(1)\n",
    "            \n",
    "            ## instead of append like instruct image output words.. instruct image w1 out, instruct image w2 output ..\n",
    "            x = torch.cat((x, caption_word_embedding), dim=1)\n",
    "            \n",
    "            loss_val = F.cross_entropy(out_phi[:, -1, :], caption_word_token, \n",
    "                        ignore_index=self.tokenizer.pad_token_id)\n",
    "            \n",
    "            loss += loss_val\n",
    "            \n",
    "            if word_output_pred_tokens is None: \n",
    "                word_output_pred_tokens = next_word.unsqueeze(1) \n",
    "            else:\n",
    "\n",
    "                word_output_pred_tokens = torch.cat((word_output_pred_tokens, next_word.unsqueeze(1)), dim=1)\n",
    "        \n",
    "        return loss/idx, word_output_pred_tokens\n",
    "\n",
    "\n",
    "torch.set_grad_enabled(True)  \n",
    "phi2_projection_model = Phi2wrapper().to(device=device)\n",
    "\n",
    "## Freezing phi-2 for projection layer training \n",
    "for name, param in phi2_projection_model.named_parameters():\n",
    "    if \"phi2_model\" in name:\n",
    "        param.requires_grad = False\n",
    "    else: \n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class SimpleResBlock(nn.Module):\n",
    "#     def __init__(self, input_size):\n",
    "#         super().__init__()\n",
    "#         self.pre_norm = nn.LayerNorm(input_size)\n",
    "#         self.proj = nn.Sequential(\n",
    "#             nn.Linear(input_size, input_size),\n",
    "#             nn.GELU(),\n",
    "#             nn.Linear(input_size, input_size)\n",
    "#         )\n",
    "#     def forward(self, x):\n",
    "#         x = self.pre_norm(x)\n",
    "#         return x + self.proj(x)\n",
    "    \n",
    "# class Phi2wrapper(nn.Module):\n",
    "    \n",
    "#     #This defines the structure of the NN.\n",
    "#     def __init__(self, input_dim_CLIP=768, input_dim_phi2=2560, \n",
    "#                  phi2_model=phi2_model_pretrained, \n",
    "#                  max_token_len_data=max_token_len_data, tokenizer=tokenizer, device=device):\n",
    "        \n",
    "#         super(Phi2wrapper, self).__init__()\n",
    "\n",
    "#         self.input_dim_CLIP = input_dim_CLIP\n",
    "#         self.input_dim_phi2 = input_dim_phi2\n",
    "#         self.projection_img = nn.Linear(self.input_dim_CLIP, self.input_dim_phi2, \n",
    "#                                         bias=False)\n",
    "        \n",
    "# #         1, 49, 2560 \n",
    "# #         1, 75, 2560 <-- embedding of Image (training) x the model predict (CLIP)\n",
    "        \n",
    "# #         caption_tkens = tokenizer(caption, return_tensors=\"pt\", return_attention_mask=False)\n",
    "# #         caption_gt_embediing = phi2_model.get_input_embeddings()(torch.tensor(caption_tokens).to(self\n",
    "# #         1, 75, 2560 <-- output y \n",
    "                                                                                                                                                                                       \n",
    "#         self.resblock = SimpleResBlock(self.input_dim_phi2)\n",
    "#         self.phi2_model = phi2_model\n",
    "#         self.max_token_len_data = max_token_len_data\n",
    "#         self.tokenizer = tokenizer\n",
    "\n",
    "#         self.device = device\n",
    "\n",
    "#         bos = self.tokenizer(\"Image: \", return_tensors=\"pt\", return_attention_mask=False)\n",
    "#         eoi = self.tokenizer(\" Caption: \", return_tensors=\"pt\", return_attention_mask=False)\n",
    "    \n",
    "#         self.bos_embedding = self.phi2_model.get_input_embeddings()(bos.input_ids.to(self.device)).squeeze(0)\n",
    "#         self.eoi_embedding = self.phi2_model.get_input_embeddings()(eoi.input_ids.to(self.device)).squeeze(0)\n",
    "#         self.eos_embedding = self.phi2_model.get_input_embeddings()(torch.tensor(self.tokenizer.eos_token_id).to(self.device)).unsqueeze(0)\n",
    "\n",
    "#     def forward(self, x, input_caption):\n",
    "\n",
    "#         x = self.projection_img(x)\n",
    "#         x = self.resblock(x)\n",
    "\n",
    "#         batch_size = x.shape[0]\n",
    "\n",
    "# #         imgae_prompt_embed = x.clone()\n",
    "#         x = torch.cat((self.bos_embedding.repeat(batch_size,1,1), x, \n",
    "#                     self.eoi_embedding.repeat(batch_size,1,1)), dim=1)\n",
    "        \n",
    "#         loss = 0 \n",
    "#         word_output_pred_tokens = None\n",
    "\n",
    "#         for idx in range(input_caption.shape[1]): \n",
    "            \n",
    "# #             next_word = self.phi2_model.forward(inputs_embeds=x.to(torch.float16))[\"logits\"][:, -1, :]\n",
    "            \n",
    "#             next_word = self.phi2_model.generate(inputs_embeds=x.to(torch.float16), max_new_tokens = 1, \n",
    "#                                             output_scores=True, return_dict_in_generate = True, \n",
    "#                                             pad_token_id=self.tokenizer.pad_token_id, \n",
    "#                                             bos_token_id=self.tokenizer.bos_token_id, \n",
    "#                                             eos_token_id=self.tokenizer.eos_token_id) ## this gives first word  \n",
    "                        \n",
    "#             caption_word_token = input_caption[:,idx]\n",
    "            \n",
    "#             no_of_pad_tokens = sum(torch.eq(torch.tensor([self.tokenizer.pad_token_id]*batch_size).to(self.device), caption_word_token))\n",
    "#             if no_of_pad_tokens == torch.tensor(batch_size): \n",
    "#                 break \n",
    "            \n",
    "#             caption_word_embedding = self.phi2_model.get_input_embeddings()(caption_word_token).unsqueeze(1)\n",
    "            \n",
    "#             ## instead of append like instruct image output words.. instruct image w1 out, instruct image w2 output ..\n",
    "#             x = torch.cat((x, caption_word_embedding), dim=1)\n",
    "\n",
    "# #             caption_word_token_new = input_caption[:, :idx+1]\n",
    "# #             caption_word_embedding_new = self.phi2_model.get_input_embeddings()(caption_word_token_new)\n",
    "# #             x = torch.cat((self.bos_embedding.repeat(batch_size,1,1), imgae_prompt_embed, caption_word_embedding_new,  \n",
    "# #                     self.eoi_embedding.repeat(batch_size,1,1)), dim=1)\n",
    "\n",
    "# #             loss_val = F.cross_entropy(F.softmax(next_word, dim=-1), caption_word_token, \n",
    "# #                         ignore_index=self.tokenizer.pad_token_id, label_smoothing=0.1)\n",
    "\n",
    "#             loss_val = F.cross_entropy(next_word.scores[0], caption_word_token, \n",
    "#                         ignore_index=self.tokenizer.pad_token_id, label_smoothing=0.1)\n",
    "\n",
    "#             loss += loss_val\n",
    "            \n",
    "# #             if word_output_pred_tokens is None: \n",
    "# #                 word_output_pred_tokens = torch.argmax(next_word,dim=-1).unsqueeze(1) \n",
    "# #             else:\n",
    "\n",
    "# #                 word_output_pred_tokens = torch.cat((word_output_pred_tokens, torch.argmax(next_word,dim=-1).unsqueeze(1)), dim=1)\n",
    "    \n",
    "#             if word_output_pred_tokens is None:\n",
    "#                 word_output_pred_tokens = next_word.sequences[:, 1].unsqueeze(1)\n",
    "#             else:\n",
    "#                 word_output_pred_tokens = torch.cat((word_output_pred_tokens, next_word.sequences[:, 1].unsqueeze(1)), dim=1)\n",
    "    \n",
    "#         loss_tosend = loss/idx\n",
    "\n",
    "#         return loss_tosend, word_output_pred_tokens\n",
    "\n",
    "#         ### Without feature forcing\n",
    "#         # x = self.phi2_model.generate(inputs_embeds=x, \n",
    "#         #                              max_new_tokens=self.max_token_len_data, \n",
    "#         #                              output_scores=True, return_dict_in_generate = True, \n",
    "#         #                              pad_token_id=self.tokenizer.eos_token_id, \n",
    "#         #                              bos_token_id=self.tokenizer.bos_token_id, \n",
    "#         #                              eos_token_id=self.tokenizer.eos_token_id)\n",
    "\n",
    "#         # return x \n",
    "\n",
    "# torch.set_grad_enabled(True)  \n",
    "# phi2_projection_model = Phi2wrapper().to(device=device)\n",
    "\n",
    "# ## Freezing phi-2 for projection layer training \n",
    "# for name, param in phi2_projection_model.named_parameters():\n",
    "#     if \"phi2_model\" in name:\n",
    "#         param.requires_grad = False\n",
    "#     else: \n",
    "#         param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 59088)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size_train = 2\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size_train, shuffle=True, num_workers=8)\n",
    "\n",
    "num_batches_train_on = 30000\n",
    "num_batches_train_on, len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, \n",
    "                                    phi2_projection_model.parameters()), \n",
    "                            lr=1e-5, eps=1e-9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on epoch 0\n",
      "Loss: tensor(7.9258, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 0\n",
      "Predictions: \n",
      ". with a few of the most of the\n",
      "Gt: A room with a couch and a tv monitor \n",
      "Loss: tensor(5.6641, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 100\n",
      "Predictions: A man with a a. a. a.\n",
      "Gt: A man holding a glass of white wine.\n",
      "Loss: tensor(5.2422, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 200\n",
      "Predictions: A man bat in a a. a. a.\n",
      "Gt: A baseball player with a dirty uniform running to a base\n",
      "Loss: tensor(5.5195, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 300\n",
      "Predictions: A man man player in a net.... a\n",
      "Gt: A professional tennis player with an orange shirt and grey shorts.\n",
      "Loss: tensor(5.7734, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 400\n",
      "Predictions: A man sitting on a a.......\n",
      "Gt: A person hiking up the side of a snow covered hillside.\n",
      "Loss: tensor(5.2344, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 500\n",
      "Predictions: A man is on a street.....\n",
      "Gt: A motorcycle parked on a lush green field.\n",
      "Loss: tensor(3.9922, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 600\n",
      "Predictions: A person is a a a a a. a...\n",
      "Gt: A man riding a white surfboard on top of a wave.\n",
      "Loss: tensor(4.9062, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 700\n",
      "Predictions: A dog of of of a a. a...\n",
      "Gt: A herd of zebra walking across a dry grass field.\n",
      "Loss: tensor(4.7461, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 800\n",
      "Predictions: A man plane flying over a........\n",
      "Gt: A jet engine flying over a blue sky with white clouds.\n",
      "Loss: tensor(5.9766, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 900\n",
      "Predictions: A man is on a a a a a a............\n",
      "Gt: A cat laying down under a light blue car.\n",
      "Loss: tensor(5.4805, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 1000\n",
      "Predictions: a man is is a a. a..........\n",
      "Gt: a bird that is sitting on top of a white chair.\n",
      "Loss: tensor(4.7188, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 1100\n",
      "Predictions: A people in women sitting on a a a a. a\n",
      "Gt: Two men and a women in the middle wearing a floral top\n",
      "Loss: tensor(4.8320, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 1200\n",
      "Predictions: A and white and brown dog on a.....\n",
      "Gt: Red, yellow and purple flowers in a painted flower vase.\n",
      "Loss: tensor(4.7070, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 1300\n",
      "Predictions: A people large flowers are on a.....\n",
      "Gt: Some very pretty zebras grazing in the grass.\n",
      "Loss: tensor(4.4961, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 1400\n",
      "Predictions: A man in on a of a......\n",
      "Gt: A bend sitting in a park along a dirt road.\n",
      "Loss: tensor(5.6406, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 1500\n",
      "Predictions: A dog in on a grassy field a...\n",
      "Gt: Brown horse grazing alone in an open grassy field. \n",
      "Loss: tensor(4.5859, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 1600\n",
      "Predictions: A train train train is on a a a. a...\n",
      "Gt: a silver subway is currently not in motion \n",
      "Loss: tensor(5.3008, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 1700\n",
      "Predictions: A man holding is a a a....\n",
      "Gt: A woman that is laying down on a bench.\n",
      "Loss: tensor(4.4922, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 1800\n",
      "Predictions: A is grazing of a a a a a. a....\n",
      "Gt: Sheep out grazing in green grass on a farm \n",
      "Loss: tensor(3.6055, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 1900\n",
      "Predictions: A group man of people are on a.....\n",
      "Gt: A massive crowd of people standing on top of a sandy beach.\n",
      "Loss: tensor(4.7266, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 2000\n",
      "Predictions: A horsesbras standing in a grassland..\n",
      "Gt: three zebras some plants bushes and trees and grass\n",
      "Loss: tensor(3.9414, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 2100\n",
      "Predictions: A man white television with a a a a a\n",
      "Gt: A flat screen TV sitting in a living room.\n",
      "Loss: tensor(5.2656, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 2200\n",
      "Predictions: A man on a a a a a........\n",
      "Gt: A laptop and computer monitor sitting on a wooden desk.\n",
      "Loss: tensor(3.8594, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 2300\n",
      "Predictions: A man riding is riding a a a a.\n",
      "Gt: a person that is on a black skateboard\n",
      "Loss: tensor(6.3242, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 2400\n",
      "Predictions: Aly large with people on a a a a a\n",
      "Gt: Extremely overloaded motorcycle carrier cardboard boxes flattened for recycling.\n",
      "Loss: tensor(4.0273, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 2500\n",
      "Predictions: A man is on a a a a a a..\n",
      "Gt: A car parked behind a fence next to a red train.\n",
      "Loss: tensor(4.9414, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 2600\n",
      "Predictions: A man is is a on a a a snow a snow..\n",
      "Gt: a dog that is running around with a frizbee\n",
      "Loss: tensor(4.1992, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 2700\n",
      "Predictions: A tall tower in the a a a a......\n",
      "Gt: A clock tower is lit at night with people looking at it.\n",
      "Loss: tensor(3.9219, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 2800\n",
      "Predictions: A bunch of fruit on a a a a a..\n",
      "Gt: A bowl of apples sits on a blue tablecloth. \n",
      "Loss: tensor(3.6738, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 2900\n",
      "Predictions: A bathroom is in a........\n",
      "Gt: A toilet seat is up in a small bathroom. \n",
      "Loss: tensor(4.0977, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 3000\n",
      "Predictions: A plate is is a a a a a a a a.\n",
      "Gt: A knife that is on top of an apple.\n",
      "Loss: tensor(5.9102, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 3100\n",
      "Predictions: A is a a a a.........\n",
      "Gt: this is a plane flying above a rusty bridge\n",
      "Loss: tensor(3.3262, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 3200\n",
      "Predictions: A manbikeist riding a a a a a..\n",
      "Gt: A motorcyclist speeds around a turn on a road,\n",
      "Loss: tensor(3.4355, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 3300\n",
      "Predictions: A dogs playing playing on in a......\n",
      "Gt: Two dogs are playing with a frisbee in the grass.\n",
      "Loss: tensor(4.4141, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 3400\n",
      "Predictions: A bathroom girl is sitting on a a a......\n",
      "Gt: The young child is lifting up the seat of a toilet. \n",
      "Loss: tensor(3.7168, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 3500\n",
      "Predictions: A man group tower in front of a a....\n",
      "Gt: A large clock sitting in the middle of a shopping center.\n",
      "Loss: tensor(4.4805, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 3600\n",
      "Predictions: A room room with a a........\n",
      "Gt: A living room filled with furniture and a lamp.\n",
      "Loss: tensor(5.1992, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 3700\n",
      "Predictions: A plate up of of a of a a of a\n",
      "Gt: a close up of two plates on food on a table\n",
      "Loss: tensor(3.9023, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 3800\n",
      "Predictions: A man riding is riding a a a a a.....\n",
      "Gt: a man that is next to a big brown horse\n",
      "Loss: tensor(4.3867, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 3900\n",
      "Predictions: A man is sitting on a a a......\n",
      "Gt: A guitar and a frisbee laying on a bed. \n",
      "Loss: tensor(3.7266, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 4000\n",
      "Predictions: A tennis is on a a tennis court....\n",
      "Gt: A man standing on a tennis court holding a racquet.\n",
      "Loss: tensor(5.4141, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 4100\n",
      "Predictions: AIN and in a a a......\n",
      "Gt: Vines growing up the pole of a stop sign\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(4.5898, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 4200\n",
      "Predictions: A plate with on a a plate......\n",
      "Gt: A pizza sitting on top of a wooden cutting board.\n",
      "Loss: tensor(4.2969, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 4300\n",
      "Predictions: A baby girl playing with a toy...\n",
      "Gt: a little kid is brushing his teeth and smiling\n",
      "Loss: tensor(5.1016, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 4400\n",
      "Predictions: Aicy flying over a a a beach..........\n",
      "Gt: Birds flying over a sandy beach and landing on a platform.\n",
      "Loss: tensor(4.0078, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 4500\n",
      "Predictions: A man man a on a a a. a......\n",
      "Gt: a black train with a red car and three people next to it\n",
      "Loss: tensor(3.9727, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 4600\n",
      "Predictions: A man bus bus with a on a.....\n",
      "Gt: A yellow school bus parked in a parking lot at night.\n",
      "Loss: tensor(3.8340, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 4700\n",
      "Predictions: A man holding a a a a a a a..\n",
      "Gt: A man eating food out of a wrapper.\n",
      "Loss: tensor(5.3203, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 4800\n",
      "Predictions: A girULT ABOB A BEE A BEE.\n",
      "Gt: A ADULT BROWN BEAR IS IN THE GRASS\n",
      "Loss: tensor(3.6387, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 4900\n",
      "Predictions: A woman holding a phone in......\n",
      "Gt: A person holding a smart device in their hands.\n",
      "Loss: tensor(4.3984, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 5000\n",
      "Predictions: A are around a table a a a a....\n",
      "Gt: People gather around a long table spread with wires and electronic gadgets.\n",
      "Loss: tensor(4.0430, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 5100\n",
      "Predictions: A woman of people sitting on a a table....\n",
      "Gt: A couple of women laying in the back of a limo.\n",
      "Loss: tensor(4.4102, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 5200\n",
      "Predictions: A elephants walking on a a of.....\n",
      "Gt: Three elephants walking in their designated area in a zoo.\n",
      "Loss: tensor(4.5039, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 5300\n",
      "Predictions: A bathroom with a with a toilet a sink..  a.\n",
      "Gt: a bathroom wih a big mirror and a tv attached in the corner\n",
      "Loss: tensor(5.4141, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 5400\n",
      "Predictions: A man and wooden, and a table........\n",
      "Gt: A damaged, leather suit case sitting on a dirty sidewalk.\n",
      "Loss: tensor(3.6094, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 5500\n",
      "Predictions: A kitchen with a countertop and a........\n",
      "Gt: A kitchen with wood floors and a stove top white oven.\n",
      "Loss: tensor(5.0039, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 5600\n",
      "Predictions: A table holding in front of a a a table of of......\n",
      "Gt: A woman standing at a table covered in desserts.\n",
      "Loss: tensor(5.7383, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 5700\n",
      "Predictions: A man standing at a a a a a.....\n",
      "Gt: A girl looking a a beautiful view of the Rockies. \n",
      "Loss: tensor(4.3242, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 5800\n",
      "Predictions: A man holding eating a a a a a.\n",
      "Gt: A woman is eating something at a table.\n",
      "Loss: tensor(4.6719, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 5900\n",
      "Predictions: A cat is on a a a a a...\n",
      "Gt: A cat sleeping on top of a stereo by a plastic clock\n",
      "Loss: tensor(4.0156, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 6000\n",
      "Predictions: A people riding a a a a a a. a\n",
      "Gt: some people one is on a white and red scooter\n",
      "Loss: tensor(5.3047, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 6100\n",
      "Predictions: A womanASS OF OF A VENDERS. a\n",
      "Gt: A GLASS OF WINE IS ON THE TABLE \n",
      "Loss: tensor(4.8789, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 6200\n",
      "Predictions: A gir gir bear is in a a a....\n",
      "Gt: A young black bear moves across a grassy field.\n",
      "Loss: tensor(4.5273, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 6300\n",
      "Predictions: A man of people are on a a a....\n",
      "Gt: A couple of guys flying a kite at water's edge.\n",
      "Loss: tensor(4.3945, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 6400\n",
      "Predictions: a group of people skiing snow on a a a......\n",
      "Gt: A couple of people riding skis on top of snow covered ground.\n",
      "Loss: tensor(4.3242, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 6500\n",
      "Predictions: A white of people sitting on a of...\n",
      "Gt: a group of urinals is near the trees\n",
      "Loss: tensor(4.2500, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 6600\n",
      "Predictions: A train and is on a a a a....\n",
      "Gt: The red train is traveling over the elevated bridge.\n",
      "Loss: tensor(3.2793, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 6700\n",
      "Predictions: Aully- cat sitting on a a a a...\n",
      "Gt: Fully grown cat laying down on top of a car. \n",
      "Loss: tensor(3.9980, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 6800\n",
      "Predictions: A woman holding a a a a.......\n",
      "Gt: A woman in a yellow jacket standing against a concrete wall.\n",
      "Loss: tensor(5., device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 6900\n",
      "Predictions: A cat dog lying on a bed......\n",
      "Gt: a little dog with a sweater while sitting    on the bed \n",
      "Loss: tensor(4.0664, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 7000\n",
      "Predictions: A group is down on a a a beach a... beach.\n",
      "Gt: A man bent over looking down on the beach while holding a baseball bat.\n",
      "Loss: tensor(2.6113, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 7100\n",
      "Predictions: A man holding a kite in a sky....\n",
      "Gt: A person flying a kite through a blue sky.\n",
      "Loss: tensor(3.8418, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 7200\n",
      "Predictions: A bathroom bathroom with a a toilet and a.....\n",
      "Gt: A white restroom contains a toilet, a sink, and a shower.\n",
      "Loss: tensor(4.0664, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 7300\n",
      "Predictions: A man is on a a a a.......\n",
      "Gt: A man sleeping in a bed with a cat next to him.\n",
      "Loss: tensor(4.3281, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 7400\n",
      "Predictions: Aumbnail train train a train a a train station a\n",
      "Gt: thi8s is a train coming down the tracks\n",
      "Loss: tensor(4.9180, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 7500\n",
      "Predictions: A man man is riding a a a a a......\n",
      "Gt: A young boy is herding cattle down a dirt road.\n",
      "Loss: tensor(4.5234, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 7600\n",
      "Predictions: A woman is a man sitting on a a a....\n",
      "Gt: A woman and man smiling at the camera.\n",
      "Loss: tensor(3.9629, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 7700\n",
      "Predictions: A brown beareddy bear is sitting on a a a a\n",
      "Gt: A brown teddy bear laying in bed under a blanket.\n",
      "Loss: tensor(5.0195, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 7800\n",
      "Predictions: A group with a a a a a a..\n",
      "Gt: a lake is close to the downtown area of a city\n",
      "Loss: tensor(5.0703, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 7900\n",
      "Predictions: A dog dog cat is sitting on a a a a a.\n",
      "Gt: A small white dog tied up to a red fire hydrant.\n",
      "Loss: tensor(4.9609, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 8000\n",
      "Predictions: A man is a a a a a a...............\n",
      "Gt: A man on a skateboard, riding in the street with a person on a motorbike in the close foreground. \n",
      "Loss: tensor(4.5703, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 8100\n",
      "Predictions: A fighter flying flying in the sky. sky....\n",
      "Gt: Two planes are very close together in the blue sky.\n",
      "Loss: tensor(4.1992, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 8200\n",
      "Predictions: A women in on a kitchen a.........\n",
      "Gt: Three women working hard to prepare food in big pots.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(4.8945, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 8300\n",
      "Predictions: A large of cows in a a a a a......\n",
      "Gt: A group of cows grazing in trash next to wall.\n",
      "Loss: tensor(2.9121, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 8400\n",
      "Predictions: A man of people playing baseball in a a a..\n",
      "Gt: A couple of people playing a game of frisbee.\n",
      "Loss: tensor(4.5352, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 8500\n",
      "Predictions: A man riding a motorcycle on a a street a.........\n",
      "Gt: A man riding on the back of a motorcycle while towing a man on a skateboard.\n",
      "Loss: tensor(4.2344, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 8600\n",
      "Predictions: A man is standing on a a a a....\n",
      "Gt: A man is standing next to a tree with a surfboard.\n",
      "Loss: tensor(7.5664, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 8700\n",
      "Predictions: A red sign with a a a a. a...\n",
      "Gt: A white sign that reads \" You Are Going To Be Alright \".\n",
      "Loss: tensor(5.3281, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 8800\n",
      "Predictions: A motorcycle riding on a a bike a a....\n",
      "Gt: a guy sitting on a motor cycle next to some trees\n",
      "Loss: tensor(4.2031, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 8900\n",
      "Predictions: A old street meter with a a a a a\n",
      "Gt: An old parking meter with some rust on it\n",
      "Loss: tensor(4.2500, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 9000\n",
      "Predictions: A woman is a phone in a a....\n",
      "Gt: A woman with a concerned look talking on a cell phone.\n",
      "Loss: tensor(4.3281, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 9100\n",
      "Predictions: A man is on a a a a beach....\n",
      "Gt: a man standing on an upside down surfboard on the sand \n",
      "Loss: tensor(6.0117, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 9200\n",
      "Predictions: Aronics equipment on a desk computer....\n",
      "Gt: Electronic equipment and notebook with notes on desktop.\n",
      "Loss: tensor(4.4336, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 9300\n",
      "Predictions: A woman holding a plate of food on in a a..\n",
      "Gt: a woman puts a trey of food inside of an oven \n",
      "Loss: tensor(5.0547, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 9400\n",
      "Predictions: A person of on a a a a......\n",
      "Gt: A painting sitting on an easel    next to a parking meter.\n",
      "Loss: tensor(4.1211, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 9500\n",
      "Predictions: A skate riding a skateboard on a a a...\n",
      "Gt: A man with a skateboard that is jumping in the air.\n",
      "Loss: tensor(3.5527, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 9600\n",
      "Predictions: A dog dog dog is on a a a....\n",
      "Gt: A small brown dog sleeping on top of a white chair.\n",
      "Loss: tensor(2.9727, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 9700\n",
      "Predictions: A ze and white zebras standing in a grass..\n",
      "Gt: Four black and white zebras standing next to each other.\n",
      "Loss: tensor(4.8125, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 9800\n",
      "Predictions: A is a woman standing on a a a a.\n",
      "Gt: there is a woman smiling and holding a large back pack\n",
      "Loss: tensor(5.1562, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 9900\n",
      "Predictions: A man holding a car a phone phone......\n",
      "Gt: a man repairing his cell phone on public transportation\n",
      "Loss: tensor(3.6777, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 10000\n",
      "Predictions: A with a living room with a a and a\n",
      "Gt: room with a baby crib and purple chair\n",
      "Loss: tensor(3.9199, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 10100\n",
      "Predictions: A kitchentop with a of a a and...\n",
      "Gt: A counter topped with different condiments next to a sink.\n",
      "Loss: tensor(3.7832, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 10200\n",
      "Predictions: A boy boy holding a a a a a....\n",
      "Gt: A little boy in a red shirt is holding a hot dog.\n",
      "Loss: tensor(4.1758, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 10300\n",
      "Predictions: A personfer riding a a wave on a beach..\n",
      "Gt: A surfer hangs ten on a wave close to shore.\n",
      "Loss: tensor(5.0820, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 10400\n",
      "Predictions: A man playing a field a a a a............\n",
      "Gt: A person in red and black reaching for a person in white and black who has a Frisbee.\n",
      "Loss: tensor(3.8613, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 10500\n",
      "Predictions: A white bird bird on a a snow a......\n",
      "Gt: A large adorable bird sitting in front of a white car on the snow.\n",
      "Loss: tensor(3.8887, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 10600\n",
      "Predictions: A group is a sheep a a a a......\n",
      "Gt: A person leading a herd of sheep with a dog.\n",
      "Loss: tensor(4.2539, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 10700\n",
      "Predictions: A man riding on a a a a a..\n",
      "Gt: a man getting chased by some kind of animals\n",
      "Loss: tensor(4.1055, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 10800\n",
      "Predictions: A of a with a a a a a.......\n",
      "Gt: Picture of truck on the other side of a fence in front of a building.\n",
      "Loss: tensor(4.7695, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 10900\n",
      "Predictions: A elephantsele elephants standing on a a a....\n",
      "Gt: Two    large elephants laying down in the dirt.\n",
      "Loss: tensor(3.8340, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 11000\n",
      "Predictions: A man is a skateboard on a a a...\n",
      "Gt: A kid doing a trick on a skateboard behind a building.\n",
      "Loss: tensor(4.1602, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 11100\n",
      "Predictions: A dog is a a a a a a..\n",
      "Gt: A dog holding a frisbee on a dirt road\n",
      "Loss: tensor(4.0391, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 11200\n",
      "Predictions: A outfieldermpire holding a baseball bat a a. a...\n",
      "Gt: An umpire, catcher, and a player standing on a field.\n",
      "Loss: tensor(6.1758, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 11300\n",
      "Predictions: A plate of food with a a a a..............\n",
      "Gt: A plate of chinese food sitting on a table.\n",
      "Loss: tensor(3.9824, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 11400\n",
      "Predictions: A bird flying flying over a water a a.........\n",
      "Gt: A bird is sitting on the edge of some wood on the side of a large lake.\n",
      "Loss: tensor(3.5684, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 11500\n",
      "Predictions: A bird bird bird flying over a water....\n",
      "Gt: a single white bird flying over the water towards the rocks \n",
      "Loss: tensor(3.8027, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 11600\n",
      "Predictions: A bathroom sink with a sink and sink a......\n",
      "Gt: A white bathroom sink with a toothbrush and orange on it.\n",
      "Loss: tensor(3.0137, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 11700\n",
      "Predictions: A plate with with a a and a...\n",
      "Gt: A sandwich is shown on a plate with fires.\n",
      "Loss: tensor(4., device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 11800\n",
      "Predictions: A boat is on the water a the.....\n",
      "Gt: A boat is in the water close to a housing lined shore.\n",
      "Loss: tensor(5.0078, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 11900\n",
      "Predictions: A gas of a gas station with a a and......\n",
      "Gt: A picture of a group of mini car meters lined up on a shelf. \n",
      "Loss: tensor(3.3770, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 12000\n",
      "Predictions: A sign sign sign is a a street....\n",
      "Gt: The electronic stop sign is not flashing on a cloudy day.\n",
      "Loss: tensor(3.2480, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 12100\n",
      "Predictions: A man is on a beach a a beach.....\n",
      "Gt: A man standing on top of a sandy beach next to the ocean.\n",
      "Loss: tensor(5.6602, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 12200\n",
      "Predictions: A man is face is a a a a a a.............\n",
      "Gt: A man's legs are laying on a bed as he watches a game called \"Avengers\" on the screen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(3.1680, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 12300\n",
      "Predictions: A bottle of bottles and on a a a..\n",
      "Gt: a group of bottles and cans on a refrigerator shelf.\n",
      "Loss: tensor(6.1172, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 12400\n",
      "Predictions: A person is flying a over a a a....\n",
      "Gt: a man is out parasailing at the beach\n",
      "Loss: tensor(3.1270, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 12500\n",
      "Predictions: A group of children playing on a a a..\n",
      "Gt: A group of children standing around a woman.\n",
      "Loss: tensor(4.5664, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 12600\n",
      "Predictions: A red sign on a street a. street\n",
      "Gt: a street sign sits on a cement ball \n",
      "Loss: tensor(4.4023, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 12700\n",
      "Predictions: A dogs are in a a a a grass...\n",
      "Gt: Two dogs playing Frisbee in an open field.\n",
      "Loss: tensor(4.7891, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 12800\n",
      "Predictions: A bus bus white bus with a a a....\n",
      "Gt: A pink, white and blue bus is by a small building.\n",
      "Loss: tensor(5.0586, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 12900\n",
      "Predictions: A people shirts hanging on a a.....\n",
      "Gt: Different colored ties hang near two old picture frames.\n",
      "Loss: tensor(3.7734, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 13000\n",
      "Predictions: A plateason of vegetables and food on on a a.\n",
      "Gt: A mixtures of broccoli and other veggies covered in sauce.\n",
      "Loss: tensor(3.7383, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 13100\n",
      "Predictions: A living with a a a a a a. a\n",
      "Gt: A room with marble floors and the door open.\n",
      "Loss: tensor(5.4336, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 13200\n",
      "Predictions: A kitchen kitchen table with a a a a.....\n",
      "Gt: A hard wood floor topped with a table and an old fashioned stove.\n",
      "Loss: tensor(3.5332, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 13300\n",
      "Predictions: A plate plate with a a and a...\n",
      "Gt: A white plate with meat covered in gravy and vegetables.\n",
      "Loss: tensor(3.5957, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 13400\n",
      "Predictions: A man is on a a a a water....\n",
      "Gt: A person sitting on rocks near the water holding a surfboard.\n",
      "Loss: tensor(3.5527, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 13500\n",
      "Predictions: A young boy playing with a a a a....\n",
      "Gt: A young boy holding a ball on a grassy green field.\n",
      "Loss: tensor(2.7363, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 13600\n",
      "Predictions: A group of people flying in a a a a.\n",
      "Gt: A group of people that are flying kites.\n",
      "Loss: tensor(3.8203, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 13700\n",
      "Predictions: A plate up of a plate with a a a..\n",
      "Gt: a close up of a plate of macaroni shells \n",
      "Loss: tensor(4.8438, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 13800\n",
      "Predictions: A people walking in umbrella umbrella umbrella umbrella......\n",
      "Gt: Two people walk on a path carrying umbrellas.\n",
      "Loss: tensor(4.3125, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 13900\n",
      "Predictions: A pizza pizza pizza sitting on a a a a.....\n",
      "Gt: A large cheesy pizza is in a microwave.\n",
      "Loss: tensor(5.1172, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 14000\n",
      "Predictions: A pizza pizza with a on a a on...\n",
      "Gt: A small pizza split into six slices with one missing.\n",
      "Loss: tensor(3.8418, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 14100\n",
      "Predictions: A man riding a a skateboard on a a...\n",
      "Gt: A man flipping a skateboard in the middle of the street.\n",
      "Loss: tensor(4.8555, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 14200\n",
      "Predictions: A group of a group of people riding on a a a..\n",
      "Gt: A photo of two motorcycles under a large umbrella taken from a car.\n",
      "Loss: tensor(4.5664, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 14300\n",
      "Predictions: A pizza is on a a a a......\n",
      "Gt: The pizza is prepared and waiting on the table to be eaten. \n",
      "Loss: tensor(3.3809, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 14400\n",
      "Predictions: A yellow of traffic signs on a street a.\n",
      "Gt: A variety of street signs with trees in the background\n",
      "Loss: tensor(3.2246, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 14500\n",
      "Predictions: A cat cat sitting on a a a a a\n",
      "Gt: A fluffy cat sitting on the edge of a table\n",
      "Loss: tensor(3.2656, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 14600\n",
      "Predictions: A man is a trick on a a a...\n",
      "Gt: A person does a skateboard trick over a bush. \n",
      "Loss: tensor(4.1172, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 14700\n",
      "Predictions: A bird bird is sitting on a branch a a....\n",
      "Gt: A small bird sitting on top of brown soil.\n",
      "Loss: tensor(3.3496, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 14800\n",
      "Predictions: A dog dog sitting on a a a a\n",
      "Gt: a brown dog is laying on a coach\n",
      "Loss: tensor(3.4219, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 14900\n",
      "Predictions: A people of food on a a a..\n",
      "Gt: Many plates of different foods are on the table.\n",
      "Loss: tensor(5.3906, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 15000\n",
      "Predictions: A bear of of a bear a a a\n",
      "Gt: The looking back to search for possible prey.\n",
      "Loss: tensor(3.8457, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 15100\n",
      "Predictions: A computer computer with a on a desk on...\n",
      "Gt: A desktop computer sitting on top of a desk.\n",
      "Loss: tensor(5.1523, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 15200\n",
      "Predictions: A table on on a a a a a......\n",
      "Gt: A clock reads almost 3 o clock above a dining room table\n",
      "Loss: tensor(5.1250, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 15300\n",
      "Predictions: A man is for a a a a a.....\n",
      "Gt: A man reaches as high as he can to hit a tennis ball.\n",
      "Loss: tensor(3.4043, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 15400\n",
      "Predictions: Aows grazing in a field a field a..\n",
      "Gt: Cows grazing in a field on a cloudy day.\n",
      "Loss: tensor(3.6758, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 15500\n",
      "Predictions: A laptop mouse on a a a desk...\n",
      "Gt: A computer keyboard sitting next to a    computer mouse.\n",
      "Loss: tensor(4.0234, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 15600\n",
      "Predictions: A streetened tree on a street a.......\n",
      "Gt: A christmas tree in an area of a large city.\n",
      "Loss: tensor(5.8242, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 15700\n",
      "Predictions: A am a to a a a a a a..............\n",
      "Gt: I am unable to see the image above.\n",
      "Loss: tensor(3.5605, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 15800\n",
      "Predictions: A coupleers are riding a the a the a.......\n",
      "Gt: The surfers are waiting in line the surf the small waves in the water. \n",
      "Loss: tensor(5.2461, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 15900\n",
      "Predictions: A man is a umbrella umbrella umbrella a a....\n",
      "Gt: A person holding an umbrella in front of gates\n",
      "Loss: tensor(3.4023, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 16000\n",
      "Predictions: A man playing a tennis court tennis a tennis.\n",
      "Gt: A man on a court with a tennis racket.\n",
      "Loss: tensor(4.6484, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 16100\n",
      "Predictions: A pair of of of a a a a......\n",
      "Gt: A pile of hair, scissors, razor, hand mirror and larger mirror.\n",
      "Loss: tensor(4.2930, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 16200\n",
      "Predictions: A and a game with a a a a.....\n",
      "Gt: Man playing video game near group of people on sofa. \n",
      "Loss: tensor(3.5391, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 16300\n",
      "Predictions: A kitchen of people cooking in a kitchen.......\n",
      "Gt: a group of people standing around a counter \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(5.3320, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 16400\n",
      "Predictions: A group beach with a a a flying a......\n",
      "Gt: A sandy beach next to the ocean under a sky filled with kites.\n",
      "Loss: tensor(3.6348, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 16500\n",
      "Predictions: A man playing on a a a a a a..\n",
      "Gt: A man sitting at a park working on a laptop computer.\n",
      "Loss: tensor(3.1699, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 16600\n",
      "Predictions: A laptop sitting a on a a a....\n",
      "Gt: A laptop and some computers on a desk.\n",
      "Loss: tensor(4.1406, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 16700\n",
      "Predictions: A stop of red and a a a a a a....\n",
      "Gt: a couple of street signs on a pole outside\n",
      "Loss: tensor(4.3320, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 16800\n",
      "Predictions: A group and woman holding a a a a...\n",
      "Gt: A man and a little girl holding game controllers.\n",
      "Loss: tensor(4.8594, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 16900\n",
      "Predictions: A man riding a horse a a a a..\n",
      "Gt: A person riding a brown horse in motion.\n",
      "Loss: tensor(6.2617, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 17000\n",
      "Predictions: A kitchen with a kitchen and kitchen.....\n",
      "Gt: Commercial kitchen with wood fired oven and lots of shelving.\n",
      "Loss: tensor(2.8867, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 17100\n",
      "Predictions: A man dog sitting on a a a a.\n",
      "Gt: A large sandwich sitting on top of a table.\n",
      "Loss: tensor(2.6914, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 17200\n",
      "Predictions: A train is through a a a a.....\n",
      "Gt: A train moving on train tracks along a beach. \n",
      "Loss: tensor(2.8047, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 17300\n",
      "Predictions: A large airplane airplane flying in the sky. sky.\n",
      "Gt: A white jet airliner flying through a cloudy sky.\n",
      "Loss: tensor(4.9180, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 17400\n",
      "Predictions: A walking a umbrella walking in rain......\n",
      "Gt: Person holding an umbrella crossing a city street in the rain.\n",
      "Loss: tensor(3.4453, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 17500\n",
      "Predictions: A little girl holding a a a a a..\n",
      "Gt: A little girl is eating a chocolate doughnut.\n",
      "Loss: tensor(3.5566, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 17600\n",
      "Predictions: A man man walking down a street a a..\n",
      "Gt: a elderly man walking across the street with traffic\n",
      "Loss: tensor(2.8418, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 17700\n",
      "Predictions: A bathroom and after picture of a bathroom.\n",
      "Gt: A before and after photograph of a bathroom.\n",
      "Loss: tensor(3.6348, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 17800\n",
      "Predictions: A laptop with with a laptop and a laptop.\n",
      "Gt: A table topped with two open laptop computers.\n",
      "Loss: tensor(4.3086, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 17900\n",
      "Predictions: A man is a hot dog in a a a....\n",
      "Gt: A man enjoys a burrito in a small restaurant. \n",
      "Loss: tensor(4.0039, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 18000\n",
      "Predictions: A plate table with a a a a........\n",
      "Gt: A wooden table with a white plate with a doughnut on top of it.\n",
      "Loss: tensor(3.5801, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 18100\n",
      "Predictions: Alyites flying flying in sky sky sky..\n",
      "Gt: Unique kites fly in the sky above an event.\n",
      "Loss: tensor(4.9141, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 18200\n",
      "Predictions: A red fire red fire a on a a. a street....\n",
      "Gt: A yellow and blue fire hydrant sitting on a sidewalk.\n",
      "Loss: tensor(5.0508, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 18300\n",
      "Predictions: A plate of a of of and vegetables.......\n",
      "Gt: A plate with broccoli, grean beans, noodles and an egg roll.\n",
      "Loss: tensor(3.8223, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 18400\n",
      "Predictions: A boy wearing a a a a a a.\n",
      "Gt: a child in a stroller wearing a tie \n",
      "Loss: tensor(2.8672, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 18500\n",
      "Predictions: A man holding a suit holding a a a a...\n",
      "Gt: A man in a t shirt is holding a frisbee.\n",
      "Loss: tensor(3.8809, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 18600\n",
      "Predictions: A giraffes standing in a a a a.....\n",
      "Gt: two giraffes in a field near wood and trees\n",
      "Loss: tensor(3.3223, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 18700\n",
      "Predictions: A cat cat cat sitting on a car a.\n",
      "Gt: A large yellow cat laying on a green car.\n",
      "Loss: tensor(5.4414, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 18800\n",
      "Predictions: A man standing a a a a a a.....\n",
      "Gt: A cow shares the street with merchants and cyclists in an Indian marketplace.\n",
      "Loss: tensor(5.3125, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 18900\n",
      "Predictions: A standing on a a a a a a......\n",
      "Gt: Guy sitting on ground in the middle of the street with traffic light behind him\n",
      "Loss: tensor(3.9121, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 19000\n",
      "Predictions: A man is on a a a a dog a a bed\n",
      "Gt: A man laying in bed while hugging a large brown dog.\n",
      "Loss: tensor(3.7480, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 19100\n",
      "Predictions: A bed bed of a bed with a a.....\n",
      "Gt: A beautiful view of a bed in a well lit area. \n",
      "Loss: tensor(3.7812, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 19200\n",
      "Predictions: A group of sheep grazing in a grass field.....\n",
      "Gt: a number of sheep in a field on a hill\n",
      "Loss: tensor(4.2031, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 19300\n",
      "Predictions: A dog is a a a a a a a.....\n",
      "Gt: A person wears a large cat costume to entertain children.\n",
      "Loss: tensor(3.6934, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 19400\n",
      "Predictions: A giraffes standing in a a a..\n",
      "Gt: Four giraffes in the wild eating from trees.\n",
      "Loss: tensor(2.8984, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 19500\n",
      "Predictions: A street light with a a a street...\n",
      "Gt: A traffic light sitting on top of a street sign,\n",
      "Loss: tensor(3.6055, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 19600\n",
      "Predictions: A woman woman group of people sitting a table..\n",
      "Gt: A very big dining table with some people at it.\n",
      "Loss: tensor(3.6855, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 19700\n",
      "Predictions: A bathroom with in a a a a...\n",
      "Gt: A toilet sitting next to a shower and a sink.\n",
      "Loss: tensor(3.2754, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 19800\n",
      "Predictions: A men standing playing a video a a a.....\n",
      "Gt: Two people are in a living room playing a Wii game. \n",
      "Loss: tensor(4.6016, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 19900\n",
      "Predictions: A clock is the water of the city......\n",
      "Gt: The bridge overpasses the water and leads to several tall buildings.\n",
      "Loss: tensor(4.0703, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 20000\n",
      "Predictions: Two z of zebras are in a a..........\n",
      "Gt: A couple of zebra standing next to a white truck.\n",
      "Loss: tensor(3.4688, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 20100\n",
      "Predictions: A people riding horseback a a a a a.\n",
      "Gt: Two men on a carriage being drawn by a horse.\n",
      "Loss: tensor(4.6016, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 20200\n",
      "Predictions: A table of filled with food and food......\n",
      "Gt: A display case in a store filled with lots of efferent foods.\n",
      "Loss: tensor(4.4375, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 20300\n",
      "Predictions: Two men riding motorcycles motorcycles a motorcycles............\n",
      "Gt: Four men riding in motor cycles and side cars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(4.8477, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 20400\n",
      "Predictions: A bathroom with in a a a a.......\n",
      "Gt: A sink sitting under a large bathroom mirror.\n",
      "Loss: tensor(4.2773, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 20500\n",
      "Predictions: A man is a motorcycle a a a a.....\n",
      "Gt: A man riding a motorcycle with a large dog on back of it.\n",
      "Loss: tensor(3.4277, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 20600\n",
      "Predictions: A cat sitting on top of a a a......\n",
      "Gt: A cat laying by a banister on top of a red suitcase.\n",
      "Loss: tensor(3.3359, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 20700\n",
      "Predictions: A man is walking down a a a a a..\n",
      "Gt: A man is walking out of a pizza restaurant with his pizza\n",
      "Loss: tensor(2.7949, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 20800\n",
      "Predictions: A red bus white bus parked a a a....\n",
      "Gt: A red and black bus parked on top of a grass field.\n",
      "Loss: tensor(3.6191, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 20900\n",
      "Predictions: A train train train is train a a....\n",
      "Gt: The large freight train is pulling many cars of cargo. \n",
      "Loss: tensor(3.6875, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 21000\n",
      "Predictions: A large that bus is on a a a....\n",
      "Gt: A car and a train on a city street.\n",
      "Loss: tensor(4.2344, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 21100\n",
      "Predictions: A of people men skateboarding skateboards.....\n",
      "Gt: Group of young men standing in fenced area with skateboards.\n",
      "Loss: tensor(3.8574, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 21200\n",
      "Predictions: A young is to ski on a snow skis.\n",
      "Gt: A woman prepares to ski on some white snow.\n",
      "Loss: tensor(3.8535, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 21300\n",
      "Predictions: A room table with a a a a.....\n",
      "Gt: A wooden desk topped with lots of clutter near a chair.\n",
      "Loss: tensor(3.9824, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 21400\n",
      "Predictions: A elephants standing a a a a a....\n",
      "Gt: Two elephants under a green tent on a sunny day. \n",
      "Loss: tensor(2.8906, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 21500\n",
      "Predictions: A group of of sheep grazing in grass......\n",
      "Gt: A field full of animals grazing on grass.\n",
      "Loss: tensor(3.6758, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 21600\n",
      "Predictions: A tooth with with a a of a...\n",
      "Gt: A table topped with personal care items and tooth paste.\n",
      "Loss: tensor(3.9512, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 21700\n",
      "Predictions: A bathroom toilet sitting in a bathroom a.....\n",
      "Gt: A white toilet in a bathroom next to a metal trash can.\n",
      "Loss: tensor(2.0645, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 21800\n",
      "Predictions: A baseball player is a a a a a a.\n",
      "Gt: A baseball player holding a baseball bat at home base.\n",
      "Loss: tensor(3.8516, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 21900\n",
      "Predictions: A dog is a fris in a field......\n",
      "Gt: A dog catching a Frisbee on a lush green grass covered park.\n",
      "Loss: tensor(3.2500, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 22000\n",
      "Predictions: A tall tower with a a a the.....\n",
      "Gt: A clock tower ascending to the sky with afternoon time\n",
      "Loss: tensor(5.0898, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 22100\n",
      "Predictions: A are a of a people a a a.....\n",
      "Gt: There are head-shots of nine professionals and a football player. \n",
      "Loss: tensor(5.0742, device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "Iteration: 22200\n",
      "Predictions: A living large living room with a couch and a.........\n",
      "Gt: A very modern living room with a black couch plus using accent colors in the shades of purple.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "vocab_size = len(tokenizer)\n",
    "\n",
    "phi2_projection_model.train()\n",
    "N_batches = len(train_dataloader)\n",
    "                \n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    print(f\"Working on epoch {epoch}\")\n",
    "\n",
    "    for iteration, batch in enumerate(train_dataloader):\n",
    "\n",
    "#         if iteration == num_batches_train_on: \n",
    "#             break \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ = batch[0]\n",
    "        gt = batch[1] \n",
    "\n",
    "        loss, output_pred_tokens = phi2_projection_model(input_.to(device), gt.to(device))\n",
    "\n",
    "#         loss.requires_grad = True ## use with geenrate \n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if (iteration % 100) == 0: \n",
    "            print(\"Loss:\", loss)\n",
    "            print(\"Iteration:\", iteration)\n",
    "            print(\"Predictions:\", tokenizer.batch_decode(output_pred_tokens)[0].rstrip())\n",
    "            print(\"Gt:\", tokenizer.batch_decode(gt)[0].split('<|endoftext|>')[0])\n",
    "\n",
    "    print(\"\")\n",
    "    print(f\"Epoch {epoch} finished\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: 1. Tensorboard, \n",
    "2. Flash attention, \n",
    "3. Phi2 (float16), \n",
    "4.model.forwrd?, \n",
    "5.eos_token to inputprompt, \n",
    "6.Onecycle policy\n",
    "7.Smaller lr?''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
